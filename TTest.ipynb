{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daG-lKwVp-MO"
      },
      "source": [
        "# T-Tests and P-Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtJudq1Op-MT"
      },
      "source": [
        "Let's say we're running an A/B test. We'll fabricate some data that randomly assigns order amounts from customers in sets A and B, with B being a little bit higher:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HHn0uQXFp-MV",
        "outputId": "0d2e04fa-8bdb-4424-9d09-0c37adf4c74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=-14.288787194607671, pvalue=4.335132763770357e-46, df=19998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "A = np.random.normal(25.0, 5.0, 10000)\n",
        "B = np.random.normal(26.0, 5.0, 10000)\n",
        "\n",
        "stats.ttest_ind(A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXkvsdD-p-Md"
      },
      "source": [
        "The t-statistic is a measure of the difference between the two sets expressed in units of standard error. Put differently, it's the size of the difference relative to the variance in the data. A high t value means there's probably a real difference between the two sets; you have \"significance\". The P-value is a measure of the probability of an observation lying at extreme t-values; so a low p-value also implies \"significance.\" If you're looking for a \"statistically significant\" result, you want to see a very low p-value and a high t-statistic (well, a high absolute value of the t-statistic more precisely). In the real world, statisticians seem to put more weight on the p-value result.\n",
        "\n",
        "Let's change things up so both A and B are just random, generated under the same parameters. So there's no \"real\" difference between the two:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NUPI4uFpp-Mg",
        "outputId": "0a7f38f6-2a33-4c6f-c758-a94fff1861a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=0.604078598097303, pvalue=0.545798240241544, df=19998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "B = np.random.normal(25.0, 5.0, 10000)\n",
        "\n",
        "stats.ttest_ind(A, B)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "gp8TgoVvp-Mh"
      },
      "source": [
        "Now, our t-statistic is much lower and our p-value is really high. This supports the null hypothesis - that there is no real difference in behavior between these two sets.\n",
        "\n",
        "Does the sample size make a difference? Let's do the same thing - where the null hypothesis is accurate - but with 10X as many samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YCvksKjdp-Mi",
        "outputId": "f844a01f-c861-4500-e569-940b1e78d689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=0.5448128420350883, pvalue=0.5858828528902673, df=199998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "A = np.random.normal(25.0, 5.0, 100000)\n",
        "B = np.random.normal(25.0, 5.0, 100000)\n",
        "\n",
        "stats.ttest_ind(A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jHJE15fp-Mj"
      },
      "source": [
        "Our p-value actually got a little lower, and the t-test a little larger, but still not enough to declare a real difference. So, you could have reached the right decision with just 10,000 samples instead of 100,000. Even a million samples doesn't help, so if we were to keep running this A/B test for years, you'd never acheive the result you're hoping for:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e_KqkzQfp-Mk",
        "outputId": "889ab8eb-02b4-40e2-cb5e-794a37c0ee3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=-0.11142308875008522, pvalue=0.911280863064592, df=1999998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "A = np.random.normal(25.0, 5.0, 1000000)\n",
        "B = np.random.normal(25.0, 5.0, 1000000)\n",
        "\n",
        "stats.ttest_ind(A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHO4H84fp-Ml"
      },
      "source": [
        "If we compare the same set to itself, by definition we get a t-statistic of 0 and p-value of 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dn2RAk4Cp-Mm",
        "outputId": "818e27f4-7fb7-40f5-8caf-21915085e59f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=0.0, pvalue=1.0, df=1999998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "stats.ttest_ind(A, A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5Outrpp-Mm"
      },
      "source": [
        "The threshold of significance on p-value is really just a judgment call. As everything is a matter of probabilities, you can never definitively say that an experiment's results are \"significant\". But you can use the t-test and p-value as a measure of signficance, and look at trends in these metrics as the experiment runs to see if there might be something real happening between the two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12XWCoLqp-Mn"
      },
      "source": [
        "## Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ZvIgR8p-Mn"
      },
      "source": [
        "Experiment with more different distributions for A and B, and see the effect it has on the t-test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QFn3JNkSp-Mo",
        "outputId": "d43c3df7-b011-4f80-eeaa-29980e677d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=-706.8462815091576, pvalue=0.0, df=1999998.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "A = np.random.normal(25.0, 5.0, 1000000)\n",
        "B = np.random.normal(30.0, 5.0, 1000000)\n",
        "\n",
        "stats.ttest_ind(A, B)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}